% ************************** Thesis Appendix A *****************************

\chapter{Reference Implementation in Python}
\begin{lstlisting}[caption=label\textunderscore security1.py ,style=chstyle, language=Python]
	"""Module to Determine classification Label Security/Certainty"""
	import numpy as np
	from scipy.spatial import distance
	
	
	class LabelSecurity:
	"""
	Label Security
	:params
	
	x_test: array, shape=[num_data,num_features]
	Where num_data is the number of samples and num_features
	refers to the number of features.
	
	class_labels: array-like, shape=[num_classes]
	Class labels of prototypes
	
	predict_results:  array-like, shape=[num_data]
	Predicted labels of the test-set
	
	model_prototypes: array-like, shape=[num_prototypes, num_features]
	
	Prototypes from the trained model using train-set, where
	num_prototypes refers to the number of prototypes
	
	x_dat : array, shape=[num_data, num_features]
	Input data
	
	fuzziness_parameter: int, optional(default=2)
	"""
	
	def __init__(self, x_test, class_labels, predict_results,
	model_prototypes, x_dat, fuzziness_parameter=2):
	self.x_test = x_test
	self.class_labels = class_labels
	self.predict_results = predict_results
	self.model_prototypes = model_prototypes
	self.x_dat = x_dat
	self.fuzziness_parameter = fuzziness_parameter
	
	def label_sec_f(self, x):
	"""
	Computes the labels security of each prediction from
	the model using the test_set
	
	:param x
	predicted labels from the model using test-set
	:return:
	labels with their security
	"""
	
	security = float
	
	# Empty list to populate with certainty of labels
	my_label_sec_list = []
	
	# loop through the test_set
	for i in range(self.x_test.shape[0]):		
	# consider respective class labels
	for label in range(self.class_labels.shape[0]):
	# checks where the predicted label equals the class label
	if self.predict_results[i] == label:
	# computes the certainty/security per predicted label
	ed_dis = distance.euclidean(self.x_test[i,
	0:self.x_dat.shape[1]],
	self.model_prototypes[label,
	0:self.x_dat.shape[1]])
	sum_dis = 0
	for j in range(
	self.model_prototypes.shape[0]):
	sum_dis += np.power(
	ed_dis /
	distance.euclidean(self.x_test[i,
	0:self.x_dat.shape[1]],
	self.model_prototypes[j,
	0:self.x_dat.shape[1]]),
	2 / (self.fuzziness_parameter - 1)
	)
	security = 1 / sum_dis
	
	my_label_sec_list.append(np.round(security, 4))  # add the computed label certainty to list above
	my_label_sec_list = np.array(my_label_sec_list)
	my_label_sec_list = my_label_sec_list.reshape(len(
	my_label_sec_list), 1)  # reshape list to 1-D array
	x = np.array(x)
	x = x.reshape(len(x), 1)  # reshape predicted labels into 1-D array
	labels_with_certainty = np.concatenate(
	(x, my_label_sec_list), axis=1)
	return labels_with_certainty
	
	
	class LabelSecurityM:
	"""
	label security for matrix GLVQ
	:parameters
	
	x_test: array, shape=[num_data, num_features]
	Where num_data refers to the number of samples and
	num_features refers to the number of features
	
	class_labels: array-like, shape=[num_classes]
	Class labels of prototypes
	
	model_prototypes: array-like, shape=[num_prototypes,
	num_features]
	
	Prototypes from the trained model using train-set, where
	num_prototypes refers to the number of prototypes
	
	model_omega: array-like, shape=[dim, num_features]
	Omega_matrix from the trained model, where dim is an int
	refers to the maximum rank
	
	x:  array, shape=[num_data, num_features]
	Input data
	
	fuzziness_parameter=int, optional(default=2)
	"""
	
	def __init__(self, x_test, class_labels, model_prototypes,
	model_omega, x, fuzziness_parameter=2):
	self.x_test = x_test
	self.class_labels = class_labels
	self.model_prototypes = model_prototypes
	self.model_omega = model_omega
	self.x = x
	self.fuzziness_parameter = fuzziness_parameter
	
	def label_security_m_f(self, x):
	"""
	Computes the label security of each prediction from 
	the model using the test_set
	:param x: predicted labels from the model using X_test
	:return: labels with their securities
	"""
	security = " "
	# Empty list to populate with the label certainty
	my_label_security_list = []
	# loop through the test set
	for i in range(len(self.x_test)):
	# considers respective class labels of prototypes
	for label in range(len(self.class_labels)):
	# checks if predicted label equals class label of prototypes
	if x[i] == label:
	
	# computes the label certainty per predicted label
	standard_ed = (self.x_test[i,
	0:self.x.shape[1]] - 
	self.model_prototypes[label,
	0:self.x.shape[1]])
	squared_ed = standard_ed.T.dot(
	self.model_omega.T).dot(
	self.model_omega).dot(standard_ed)
	sum_dis = 0
	for j in range(
	len(self.model_prototypes)):
	standard_ed1 = (self.x_test[i,
	0:self.x.shape[1]] -
	self.model_prototypes[j,
	0:self.x.shape[1]])
	sum_dis += np.power(
	squared_ed / (standard_ed1.T.dot(
	self.model_omega.T).dot(
	self.model_omega).dot(
	standard_ed1)),
	1 / (self.fuzziness_parameter - 1)
	)
	security = 1 / sum_dis
	
	# adds the computed certainty to the list
	my_label_security_list.append(np.round(security, 4))
	my_label_security_list = np.array(
	my_label_security_list)
	my_label_security_list = my_label_security_list\
	.reshape(len(my_label_security_list), 1)  # 1-D array reshape
	x = np.array(x)
	x = x.reshape(len(x), 1)  # reshape the predicted labels into 1-D array
	labels_with_certainty = np.concatenate(
	(x,my_label_security_list), axis=1)
	return labels_with_certainty
	
	
	class LabelSecurityLM:
	"""
	label security for local matrix GLVQ
	:parameters
	
	x_test: array, shape=[num_data, num_features]
	Where num_data refers to the number of samples and 
	num_features refers to the number of features
	
	class_labels: array-like, shape=[num_classes]
	Class labels of prototypes
	
	model_prototypes: array-like, shape=[num_prototypes,
	num_features]
	
	Prototypes from the trained model using train-set, where
	num_prototypes refers to the number of prototypes
	
	model_omega: array-like, shape=[dim, num_features]
	Omega_matrix from the trained model, where dim is an int 
	refers to the maximum rank
	
	x:  array, shape=[num_data, num_features]
	Input data
	
	fuzziness_parameter=int, optional(default=2)
	"""
	
	def __init__(self, x_test, class_labels, model_prototypes,
	model_omega, x, fuzziness_parameter=2):
	self.x_test = x_test
	self.class_labels = class_labels
	self.model_prototypes = model_prototypes
	self.model_omega = model_omega
	self.x = x
	self.fuzziness_parameter = fuzziness_parameter
	
	def label_security_lm_f(self, x):
	"""
	computes the label security of each prediction from
	the model using the test_set
	and returns only labels their corresponding security.
	:param x: predicted labels from the model using X_test
	:return: labels with  security
	"""
	security = " "
	# Empty list to populate with the label security
	my_label_security_list = []
	# loop through the test set
	for i in range(len(self.x_test)):
	# considers respective class labels of prototypes
	for label in range(len(self.class_labels)):
	# checks if predicted label equals class label of prototypes
	if x[i] == label:
	
	# computes the label certainty per predicted label
	standard_ed = (self.x_test[i,
	0:self.x.shape[1]]-
	self.model_prototypes[label,
	0:self.x.shape[1]])
	squared_ed = standard_ed.T.dot(
	self.model_omega[label].T).dot(
	self.model_omega[label]).dot(
	standard_ed)
	sum_dis = 0
	for j in range(len(
	self.model_prototypes)):
	standard_ed1 = (self.x_test[i,
	0:self.x.shape[1]]-
	self.model_prototypes[j,
	0:self.x.shape[1]])
	sum_dis += np.power(
	squared_ed / (standard_ed1.T.dot(
	self.model_omega[j].T).dot(
	self.model_omega[j]).dot(
	standard_ed1)),
	1 / (self.fuzziness_parameter - 1)
	)
	security = 1 / sum_dis
	
	# adds the computed certainty to the list
	my_label_security_list.append(np.round(security, 4))
	my_label_security_list = np.array(
	my_label_security_list)
	my_label_security_list = my_label_security_list\
	.reshape(len(my_label_security_list), 1)  # 1-D array reshape
	x = np.array(x)
	x = x.reshape(len(x), 1)  # reshape the predicted labels into 1-D array
	labels_with_certainty = np.concatenate(
	(x, my_label_security_list), axis=1)
	return labels_with_certainty
	
	
	if __name__ == '__main__':
	print('import module to use')
	
\end{lstlisting}

\newpage
\begin{lstlisting}[caption = contour.py, style=chstyle, language=Python]
	"""
	visualize the classification label securities
	"""
	import scipy.interpolate
	import torch
	import matplotlib
	import matplotlib.pyplot as plt
	import numpy as np
	from matplotlib.lines import Line2D
	from matplotlib.colors import ListedColormap
	
	matplotlib.style.use('default')
	class Contourrn:
	"""
	visualize the classification label securities
	"""
	def __init__(self):
	pass
	
	
	def plot_dec_boundary(self,
	x,
	y,
	model,
	model_p,
	title,
	xlabel,
	ylabel,
	model_type,
	model_index):
	
	"""
	
	:param x: X_test
	:param y: labels of the test set
	:param model: model object
	:param model_p: model prototypes
	:param title: Title of plot
	:param xlabel: Title of data dimension 1
	:param ylabel: Title of data dimension 2
	:param model_type: string: Name of model
	:param model_index: int: model index
	:return: 
	"""
	
	colors = ["r", "b", "g", "y", "m"]
	colors_ = ["r", "b", "g"]
	marker = ["*", "P", "D", "p", "H"]
	cm = ListedColormap(colors_)
	ax = plt.gca()
	z1 = model_p
	# Plotting decision regions
	x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1
	y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1
	x1, y1 = np.meshgrid(np.arange(x_min, x_max, 0.05),
	np.arange(y_min, y_max, 0.05))
	
	y_pred_1 = model.predict(torch.Tensor(
	np.c_[x1.ravel(), y1.ravel()]))
	Z1 = y_pred_1.reshape(x1.shape)
	plt.contourf(x1, y1, Z1, alpha=0.4, cmap=cm)
	# customize the lines
	# for t in cont.collections:
	#     t.set_edgecolor('face')
	#     t.set_linewidth(0)
	# plt.savefig('test')
	
	for t in range(len(y)):
	if y[t] == 0:
	s1 = ax.scatter(
	x[t, 0],
	x[t, 1],
	c='r',
	marker='v',)
	if y[t] == 1:
	s2 = ax.scatter(
	x[t, 0],
	x[t, 1],
	c='b',
	marker='v',)
	if y[t] == 2:
	s3 = ax.scatter(
	x[t, 0],
	x[t, 1],
	c='g',
	marker='v',)
	legend1 = plt.legend((s1, s2, s3),
	["Setosa", "Versicolor", "Virginica"],
	title="Iris Classes",
	loc="upper left",
	fancybox=True,
	framealpha=0.5)
	ax.add_artist(legend1)
	
	# plot learned prototypes
	t1 = ax.scatter(
	z1[0][0],
	z1[0][1],
	s=100, 
	color=colors[0], 
	marker=marker[model_index])
	t2 = ax.scatter(
	z1[1][0],
	z1[1][1], 
	s=100, 
	color=colors[1],
	marker=marker[model_index])
	t3 = ax.scatter(
	z1[2][0], 
	z1[2][1], 
	s=100, 
	color=colors[2], 
	marker=marker[model_index])
	legend2 = plt.legend(
	(t1, t2, t3),
	["Setosa ", "Versicolor ","Virginica"],
	title=f"{model_type} Prototypes", 
	loc="lower left", 
	fancybox=True, framealpha=0.5)
	ax.add_artist(legend2)
	
	plt.title(title)
	plt.xlabel(xlabel)
	plt.ylabel(ylabel)
	
	return plt.show()
	
	
	def plot__newt(self,
	x,
	y,
	label_sec,
	model_p,
	index_list,
	xlabel,
	ylabel,
	title,
	model_1,
	model_type,
	model_index,
	h):
	""" visualize classification label securities per
	class for a test set including learned prototypes 
	responsible for the classifications.
	
	:param x: X_test
	:param y: labels of the test set
	:param label_sec: List containing label securities
	:param model_p: model prototypes
	:param index_list: List containing(index of data point
	,label, label security)
	:param title: Title of Plot
	:param ylabel: Title of data dimension 2
	:param xlabel: Title of data dimension 1
	:param model_1: model understudy
	:param model_type:string : model name
	:param model_index: int : 0 for glvq, 1 for gmlvq and
	2 for celvq
	:param h: threshold security
	:return: Plot
	"""
	
	ax = plt.gca()
	k = []
	k1 = []
	colors = ["r", "b", "g", "y", "m"]
	marker = ["*", "P", "D", "p", "H"]
	z_ = label_sec
	z1 = model_p
	for j in index_list:
	k.append(x[j[0], 0])
	k1.append(x[j[0], 1])
	x1, y1 = np.linspace(
	np.min(k), np.max(k),len(k)), np.linspace(
	np.min(k1), np.max(k1), len(k1))
	x1, y1 = np.meshgrid(x1, y1)
	
	rbf = scipy.interpolate.Rbf(k, k1, z_,
	function='linear')
	zi = rbf(x1, y1)
	
	x_min, x_max = np.min(k), np.max(k)
	y_min, y_max = np.min(k1), np.max(k1)
	x11, y11 = np.meshgrid(np.arange(x_min, x_max, 0.05),
	np.arange(y_min, y_max, 0.05))
	y_pred_1 = model_1.predict(
	torch.Tensor(np.c_[x11.ravel(), y11.ravel()]))
	
	Z1 = y_pred_1.reshape(x11.shape)
	
	plt.contour(x11, y11, Z1, levels=3,
	colors = np.array([colors[0], colors[1],
	colors[1],colors[2]]))
	
	# plot the label securities regions
	plt.imshow(zi,
	vmin=np.min(z_),
	vmax=np.max(z_),
	origin='lower',
	extent=[np.min(k),
	np.max(k),
	np.min(k1),
	np.max(k1)])
	
	# plot classification label securities together with rejected classifications based on a threshold security 
	j = -1
	for j1 in index_list:
	j += 1
	if y[j] == 0 and j1[1] == 0 and j1[2] >= h:
	s1 = ax.scatter(
	x[j, 0],
	x[j, 1],
	color='r', 
	marker='v')
	if y[j] == 0 and j1[1] != 0 and j1[2] >= h:
	s1_ = ax.scatter(
	x[j, 0],
	x[j, 1], 
	color='r', 
	marker='v')
	if y[j] == 0 and j1[1] == 0 and j1[2] < h:
	s1__ = ax.scatter(
	x[j, 0],
	x[j, 1], 
	color='r', 
	marker='v', 
	edgecolor='k')
	if y[j] == 0 and j1[1] != 0 and j1[2] < h:
	s1_ = ax.scatter(
	x[j, 0], 
	x[j, 1], 
	color='r', 
	marker='v', 
	edgecolor='k')
	
	if y[j] == 1 and j1[1] == 1 and j1[2] >= h:
	s2 = ax.scatter(
	x[j, 0], 
	x[j, 1], 
	color='b', 
	marker='v')
	if y[j] == 1 and j1[1] != 1 and j1[2] >= h:
	s2_ = ax.scatter(
	x[j, 0], 
	x[j, 1], 
	color='b', 
	marker='v')
	if y[j] == 1 and j1[1] == 1 and j1[2] < h:
	s2__ = ax.scatter(
	x[j, 0], 
	x[j, 1], 
	color='b', 
	marker='v', 
	edgecolor='k')
	if y[j] == 1 and j1[1] != 1 and j1[2] < h:
	s2_ = ax.scatter(
	x[j, 0], 
	x[j, 1], 
	color='b', 
	marker='v', 
	edgecolor='k')
	
	if y[j] == 2 and j1[1] == 2 and j1[2] >= h:
	s3 = ax.scatter(
	x[j, 0],
	x[j, 1], 
	color='g', 
	marker='v')
	if y[j] == 2 and j1[1] != 2 and j1[2] >= h:
	s3_ = ax.scatter(
	x[j, 0], 
	x[j, 1], 
	color='g', 
	marker='v')
	if y[j] == 2 and j1[1] == 2 and j1[2] < h:
	s3__ = ax.scatter(
	x[j, 0], 
	x[j, 1], 
	color='g', 
	marker='v', 
	edgecolor='k')
	if y[j] == 2 and j1[1] != 2 and j1[2] < h:
	s3_ = ax.scatter(
	x[j, 0], 
	x[j, 1], 
	color='g', 
	marker='v', 
	edgecolor='k')
	
	legend1 = plt.legend((s1, s2, s3,),
	["Setosa", "Versicolor", "Virginica"],
	title="Iris Classes",
	loc="upper left", bbox_to_anchor=(-0.6, 1))
	ax.add_artist(legend1)
	
	# plot the learned prototypes
	t1 = ax.scatter(z1[0][0], 
	z1[0][1], 
	s=100, 
	color=colors[0], 
	marker=marker[model_index])
	t2 = ax.scatter(z1[1][0], 
	z1[1][1], s=100, 
	color=colors[1], 
	marker=marker[model_index])
	t3 = ax.scatter(z1[2][0], 
	z1[2][1], 
	s=100, 
	color=colors[2], 
	marker=marker[model_index])
	legend2 = plt.legend((t1, t2, t3,),
	["Setosa ", "Versicolor ", "Virginica"],
	title=f"{model_type} Prototypes", loc="lower left",
	bbox_to_anchor=(-0.6, 0.0))
	ax.add_artist(legend2)
	
	legend_list = []
	for class_, color in zip(
	["Setosa ", "Versicolor ", "Virginica"], 
	['r', 'b', 'g']):
	legend_list.append(Line2D([0], [0],
	marker='v', label=class_, ls='None',
	markerfacecolor=color,
	markeredgecolor='k'))
	legend3 = plt.legend(
	handles=legend_list,
	loc="center", bbox_to_anchor=(-0.5, 0.5),
	title='Rejected classification')
	ax.add_artist(legend3)
	
	plt.colorbar()
	plt.title(title)
	plt.xlabel(xlabel)
	plt.ylabel(ylabel)
	
	return plt.show()
	
	if __name__ == '__main__':
	print('import module to use')
	
\end{lstlisting}

\begin{comment}

\end{comment}

\begin{comment}

%\begin{lstlisting}[caption = protocert.py, style=chstyle, language=Python]
class ProtoCert:
"""
Prototype certainty and overall model certainty
:param
x_test: array, shape=[num_data,num_features]
Where num_data is the number of samples and num_features
refers to the number of features.

class_labels: array-like, shape=[num_classes]
Class labels of prototypes

predict_results:  array-like, shape=[num_data]
Predicted labels of the test-set

"""

def __init__(self, y_test, class_labels, predict_results):
self.y_test = y_test
self.class_labels = class_labels
self.predict_results = predict_results

def model_certainty_list(self, x):
"""
Determines the list of data points whose class is the
same as the class of the prototypes
:param x:
Test set class labels
:return:
List containing labels of data points whose class is
the same as the class of the prototype
"""
same_list = []
for i in range(self.predict_results.shape[0]):
if x[i] == self.predict_results[i]:
same_list.append(x[i])
return same_list

def my_proto_cert(self, x):
"""
Computes the model certainty of the respective
prototypes
:param x:
Class labels of the test set
:return:
The model certainty with respect to each prototype
"""
proto_cert_list = []
d = {i: self.model_certainty_list(x).count(i)
for i in self.model_certainty_list(x)}
# tensor so u convert it to numpy list
dict_ = {i: list(
self.predict_results.numpy()).count(i) 
for i in list(self.predict_results.numpy())}
# dict_ = {i: list(self.y_test).count(i) 
# for i in list(self.y_test)}
my_list = list(d.items())
my_list1 = list(dict_.items())
for label in range(self.class_labels.shape[0]):
for i in range(len(self.class_labels)):
if my_list[label][0] == my_list1[i][0]:
prototype_certainty = my_list[label][1] /\ 
my_list1[i][1]
proto_cert_list.append([my_list[label][0],
prototype_certainty])
return proto_cert_list

def overall_model_cert(self, x):
"""
Computes the overall model certainty taking into
consideration all respective prototype certainties
by way of average.
:param x:
Test set class labels
:return:
Overall model certainty
"""

proto_cert = self.my_proto_cert(x)
sum_ = 0
for i in range(len(self.my_proto_cert(x))):
sum_ += self.my_proto_cert(x)[i][1]
sum_proto_cert = sum_ / self.class_labels.shape[0]
return sum_proto_cert

def thresh_function(self, x, y, y_, y__, y___):
"""
:param x: predicted labels with their corresponding
securities
:param y: float: security threshold
:param y_: string: '>', '<' ,'>=' to indicate the
threshold security
:param y__: string: 's' for securities , 'i' for index
of data point, 'l' for label, 'all' for list with
(securities,indexes,labels)
:param y___: class label under consideration (None for
all labels)
:return: List containing securities( greater than or 
less than a given security thresh-hold),
"""
empty = []
empty2 = []
empty3 = []
empty4 = []
for i in range(len(x)):
if y_ == '>' and x[i][1] > y and x[i][0] == y___:
empty.append(x[i][1])
empty2.append(i)
empty3.append(x[i][0])
empty4.append([i, x[i][0], x[i][1]])
if y_ == '>' and x[i][1] > y and y___ is None:
empty.append(x[i][1])
empty2.append(i)
empty3.append(x[i][0])
empty4.append([i, x[i][0], x[i][1]])
if y_ == '>=' and x[i][1] >= y and x[i][0] == y___:
empty.append(x[i][1])
empty2.append(i)
empty3.append(x[i][0])
empty4.append([i, x[i][0], x[i][1]])
if y_ == '>=' and x[i][1] >= y and y___ is None:
empty.append(x[i][1])
empty2.append(i)
empty3.append(x[i][0])
empty4.append([i, x[i][0], x[i][1]])
if y_ == '=' and x[i][1] == y and x[i][0] == y___:
empty.append(x[i][1])
empty3.append(x[i][0])
empty2.append(i)
empty4.append([i, x[i][0], x[i][1]])
if y_ == '=' and x[i][1] == y and y___ is None:
empty.append(x[i][1])
empty2.append(i)
empty3.append(x[i][0])
empty4.append([i, x[i][0], x[i][1]])
if y_ == '<' and x[i][1] < y and x[i][0] == y___:
empty.append(x[i][1])
empty2.append(i)
empty3.append(x[i][0])
empty4.append([i, x[i][0], x[i][1]])
if y_ == '<' and x[i][1] < y and y___ is None:
empty.append(x[i][1])
empty2.append(i)
empty3.append(x[i][0])
empty4.append([i, x[i][0], x[i][1]])
if y__ == 'i':
return empty2
if y__ == 's':
return empty
if y__ == 'l':
return empty3
if y__ == 'all':
return empty4

def thresh_y_test(self, x):
"""

:param x: thresh hold index list
:return: labels with the thresh hold security
"""
empty = []
y = self.y_test
for index in x:
for i in range(len(y)):
if i == index:
empty.append(y[i])
return empty


if __name__ == '__main__':
print('import module to use')

\end{lstlisting
\end{comment}

